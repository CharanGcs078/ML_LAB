{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HQ30-SG9DNb",
        "outputId": "9030fd89-2581-4859-ad1a-6a0f925410c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[14  0  0]\n",
            " [ 1 13  0]\n",
            " [ 0  1  7]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.97        14\n",
            "           1       0.93      0.93      0.93        14\n",
            "           2       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.95      0.93      0.94        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n",
            "\n",
            "Accuracy Score: 0.9444444444444444\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_wine()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Base estimator: simple decision tree stump (depth=1)\n",
        "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "# AdaBoost model\n",
        "model = AdaBoostClassifier(estimator=base_estimator, n_estimators=50, learning_rate=1.0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Decision stump implementation\n",
        "class DecisionStump:\n",
        "    def __init__(self):\n",
        "        self.feature_index = None\n",
        "        self.threshold = None\n",
        "        self.polarity = 1\n",
        "        self.alpha = None\n",
        "\n",
        "    def predict(self, X):\n",
        "        n_samples = X.shape[0]\n",
        "        X_column = X[:, self.feature_index]\n",
        "        predictions = np.ones(n_samples)\n",
        "        if self.polarity == 1:\n",
        "            predictions[X_column < self.threshold] = -1\n",
        "        else:\n",
        "            predictions[X_column > self.threshold] = -1\n",
        "        return predictions\n",
        "\n",
        "def adaboost_train(X, y, n_clf=10):\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # Initialize weights uniformly\n",
        "    w = np.full(n_samples, (1 / n_samples))\n",
        "\n",
        "    classifiers = []\n",
        "\n",
        "    for _ in range(n_clf):\n",
        "        clf = DecisionStump()\n",
        "        min_error = float('inf')\n",
        "\n",
        "        # Find best decision stump\n",
        "        for feature_i in range(n_features):\n",
        "            X_column = X[:, feature_i]\n",
        "            thresholds = np.unique(X_column)\n",
        "            for threshold in thresholds:\n",
        "                for polarity in [1, -1]:\n",
        "                    predictions = np.ones(n_samples)\n",
        "                    if polarity == 1:\n",
        "                        predictions[X_column < threshold] = -1\n",
        "                    else:\n",
        "                        predictions[X_column > threshold] = -1\n",
        "\n",
        "                    # Calculate weighted error\n",
        "                    misclassified = w[y != predictions]\n",
        "                    error = sum(misclassified)\n",
        "\n",
        "                    if error < min_error:\n",
        "                        min_error = error\n",
        "                        clf.polarity = polarity\n",
        "                        clf.threshold = threshold\n",
        "                        clf.feature_index = feature_i\n",
        "\n",
        "        # Compute alpha\n",
        "        EPS = 1e-10  # to avoid division by zero\n",
        "        clf.alpha = 0.5 * np.log((1.0 - min_error) / (min_error + EPS))\n",
        "\n",
        "        # Predict with the best stump\n",
        "        predictions = clf.predict(X)\n",
        "\n",
        "        # Update weights\n",
        "        w *= np.exp(-clf.alpha * y * predictions)\n",
        "        w /= np.sum(w)  # normalize\n",
        "\n",
        "        classifiers.append(clf)\n",
        "\n",
        "    return classifiers\n",
        "\n",
        "def adaboost_predict(X, classifiers):\n",
        "    clf_preds = [clf.alpha * clf.predict(X) for clf in classifiers]\n",
        "    y_pred = np.sum(clf_preds, axis=0)\n",
        "    return np.sign(y_pred)\n",
        "\n",
        "# === Main ===\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Convert labels to -1 and 1 for AdaBoost\n",
        "y = np.where(y == 0, -1, 1)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train AdaBoost\n",
        "classifiers = adaboost_train(X_train, y_train, n_clf=10)\n",
        "\n",
        "# Predict test data\n",
        "y_pred = adaboost_predict(X_test, classifiers)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgtUJfzP9F0Z",
        "outputId": "310e733c-bfb1-4709-c0e5-7f6ffa713b6e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[40  3]\n",
            " [ 2 69]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.95      0.93      0.94        43\n",
            "           1       0.96      0.97      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "\n",
            "Accuracy Score: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mIxtMrl79SF2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}